Bu proje, gÃ¼venlik kameralarÄ±ndan elde edilen videolarda anormal olaylarÄ± tespit etmek amacÄ±yla geliÅŸtirilen bir video iÅŸleme sistemidir. UCF-Crime veri seti Ã¼zerinde Ã§alÄ±ÅŸÄ±lmÄ±ÅŸ ve Video Vision Transformer (ViViT) mimarisi kullanÄ±larak bir derin Ã¶ÄŸrenme modeli oluÅŸturulmuÅŸtur. Ã‡evresel gÃ¼rÃ¼ltÃ¼yÃ¼ azaltmak iÃ§in Ã¶ncelikle Mask R-CNN ile insan ve araÃ§ gibi nesnelerin bulunduÄŸu bÃ¶lgeler tespit edilmiÅŸ, ardÄ±ndan bu bÃ¶lgeler Ã¼zerinden TV-L1 yÃ¶ntemiyle optik akÄ±ÅŸ hesaplanmÄ±ÅŸtÄ±r. Elde edilen hareket bilgisi ViViT modeline giriÅŸ olarak verilmiÅŸ ve model anomalileri yÃ¼ksek doÄŸrulukla sÄ±nÄ±flandÄ±rabilmiÅŸtir. Bu yaklaÅŸÄ±m, klasik ViViT modellerine kÄ±yasla %37 daha yÃ¼ksek doÄŸruluk ve %45 daha iyi F1 skoru elde etmiÅŸtir.

---

````markdown
# ğŸ§  ViViT-Flow: Anomaly Detection in Surveillance Videos

A deep learning-based video anomaly detection pipeline using **ViViT (Video Vision Transformer)**, enhanced with **instance segmentation** and **masked optical flow** preprocessing. Applied on the **UCF-Crime dataset** for detecting real-world anomalies in surveillance footage.

---

## ğŸ“‚ Project Structure

```bash
vivit-anomaly-detection/
â”œâ”€â”€ segmentation/             # Mask R-CNN instance-level segmentation
â”œâ”€â”€ optical_flow/             # TV-L1 method for dense optical flow
â”œâ”€â”€ vivit_model/              # ViViT-B/16x2 model and fine-tuning code
â”œâ”€â”€ dataset/                  # Preprocessed UCF-Crime video clips
â”œâ”€â”€ notebooks/                # Jupyter notebooks for experiments
â”œâ”€â”€ utils/                    # Utility functions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
````

---

## ğŸ” Overview

This project proposes a novel ViViT-based anomaly detection pipeline:

1. **Mask R-CNN** is used to extract human/object regions from frames.
2. **TV-L1 optical flow** is computed over segmentation masks to focus on motion-relevant areas.
3. (u, v, g) flow triplets are fed into a ViViT-B/16x2 model pre-trained on Kinetics-400.
4. **Focal Loss** is applied to address class imbalance between normal and anomalous events.

---

## ğŸ§ª Dataset

* **UCF-Crime** dataset: 1900 surveillance videos across 13 anomaly types.
* This work uses a subset (290 videos): 145 normal, 145 anomalous.
* Frame size: **224x224**, Clip length: **32 frames**, Input shape: (3 Ã— 32 Ã— 224 Ã— 224)

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/vivit-anomaly-detection.git
cd vivit-anomaly-detection
pip install -r requirements.txt
```

---

## ğŸš€ Run Pipeline

```bash
# 1. Instance Segmentation
python segmentation/run_segmentation.py

# 2. Compute Masked Optical Flow
python optical_flow/compute_flow.py

# 3. Train ViViT Model
python vivit_model/train.py
```

You can also follow the `notebooks/ViViT_Training.ipynb` for visual, step-by-step execution.

---

## ğŸ“Š Results

### ğŸ“Œ Evaluation Metrics on UCF-Crime (Binary Classification)

| Model                 | Accuracy  | Precision | Recall    | F1-Score  | F1 (Normal) | F1 (Anomaly) |
| --------------------- | --------- | --------- | --------- | --------- | ----------- | ------------ |
| **ViViT-Flow (Ours)** | **88.3%** | **0.865** | **0.869** | **0.868** | 0.820       | 0.907        |
| ViViT (RGB-only)      | 51.3%     | 0.402     | 0.425     | 0.407     | 0.156       | 0.658        |

> âœ… Our ViViT-Flow model significantly outperforms the baseline (ViViT on raw RGB) by +37% in accuracy and +45% in F1-score.

---

### ğŸ“š Comparison with State-of-the-Art

| Method                 | Accuracy  | Precision | Recall    | F1-Score  |
| ---------------------- | --------- | --------- | --------- | --------- |
| CNN + RNN \[7]         | 82.5%     | 0.760     | 0.870     | 0.813     |
| 1D Transformer \[8]    | 80.7%     | 0.784     | 0.856     | â€“         |
| Weak Supervision \[11] | 81.2%     | 0.745     | 0.820     | 0.782     |
| **ViViT-Flow (Ours)**  | **88.3%** | **0.865** | **0.869** | **0.868** |

---

## ğŸ› ï¸ Model Details

* **Backbone**: ViViT-B/16x2 (Pretrained on Kinetics-400)
* **Loss Function**: Focal Loss (Î³ = 1.5)
* **Input**: Segmentation-masked TV-L1 optical flow (u, v, g)
* **Optimizer**: AdamW
* **Training**: 10 epochs on NVIDIA T4, batch size 8, gradient accumulation 8

---

## ğŸ’¡ Future Work

* [ ] Add video augmentation using diffusion models (for rare anomaly simulation)
* [ ] Deploy ViViT-Flow on edge devices
* [ ] Extend to multi-class anomaly detection

---

## ğŸ“œ License

MIT License - see [`LICENSE`](./LICENSE) for more info.

---

## ğŸ™ Acknowledgements

Special thanks to:

* **Dr. Erkut ArÄ±can** for mentorship and guidance
* **PyTorchVideo**, **Detectron2**, and **Hugging Face** for open-source libraries

```

---

Bu dosyayÄ± doÄŸrudan `README.md` olarak yapÄ±ÅŸtÄ±rabilirsin. EÄŸer istersen sana `.md` formatÄ±nda dosyayÄ± da verebilirim. Projeyi GitHub'a yÃ¼kledikten sonra gÃ¶rseller eklemeyi veya Ã¶rnek bir inference videosu (GIF formatÄ±nda) koymayÄ± da dÃ¼ÅŸÃ¼nebilirsin.

HazÄ±r mÄ±sÄ±n yoksa son bir gÃ¼ncelleme yapalÄ±m mÄ±?
```
---

## ğŸ§  ViViT-Based Anomaly Detection on UCF-Crime Dataset

A deep learning-based video anomaly detection pipeline using **ViViT (Video Vision Transformer)**, enhanced with **instance segmentation** and **optical flow** preprocessing. Applied on the **UCF-Crime dataset** for detecting real-world anomalies in surveillance footage.

---

### ğŸ“‚ Project Structure

```bash
vivit-anomaly-detection/
â”‚
â”œâ”€â”€ segmentation/               # Mask R-CNN for instance-level segmentation
â”œâ”€â”€ optical_flow/               # TV-L1 method to compute flow (u, v, g)
â”œâ”€â”€ vivit_model/                # ViViT model code and fine-tuning scripts
â”œâ”€â”€ dataset/                    # Preprocessed UCF-Crime clips
â”œâ”€â”€ utils/                      # Helper functions for I/O, plotting, etc.
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks for experiments
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md
```

---

### ğŸ” Project Description

This project implements an anomaly detection pipeline consisting of:

1. **Instance Segmentation** using Mask R-CNN (to extract regions of interest like humans and vehicles),
2. **TV-L1 Optical Flow** calculation masked by segmentation output,
3. Feeding optical flow triplets `(u, v, g)` into **ViViT**, a transformer-based video classifier,
4. **Fine-tuning ViViT** on the `UCF-Crime` dataset for binary anomaly classification (normal vs abnormal).

---

### ğŸ§ª Dataset

* **Dataset**: [UCF-Crime](https://www.crcv.ucf.edu/projects/real-world/)
* **Classes**: Abuse, Arson, Assault, Burglary, Explosion, Robbery, etc.
* **Input Shape**: (T, H, W, C) = (32, 224, 224, 3)

---

### ğŸ“¦ Requirements

```bash
pip install -r requirements.txt
```

Main libraries:

* PyTorch
* TorchVision
* PyTorchVideo
* OpenCV
* Detectron2 (for Mask R-CNN)
* scikit-learn
* numpy

---

### ğŸš€ How to Run

```bash
# Step 1: Segment frames using Mask R-CNN
python segmentation/run_segmentation.py

# Step 2: Compute Optical Flow (TV-L1)
python optical_flow/compute_flow.py

# Step 3: Train or Fine-Tune ViViT
python vivit_model/train.py
```

Or use `notebooks/ViViT_Training.ipynb` for step-by-step visual training.

---

### ğŸ“Š Evaluation Metrics

* Accuracy, Precision, Recall
* AUC-ROC
* Confusion Matrix


### ğŸ“œ License

MIT License - see [`LICENSE`](./LICENSE) for more information.

---

### ğŸ¤ Acknowledgements

* [ViViT Paper (Google Research)](https://arxiv.org/abs/2103.15691)
* [UCF Crime Dataset](https://www.crcv.ucf.edu/projects/real-world/)
* [PyTorchVideo](https://pytorchvideo.org/)
* [Detectron2](https://github.com/facebookresearch/detectron2)

