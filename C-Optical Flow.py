"""## **D- Vivit Model**

### 4-A â–¸ Flow-pencerelerini (32 frame) ViViT formatÄ±na dÃ¶nÃ¼ÅŸ

---
"""

# =====================================================================
# Script 4-A: Optik AkÄ±ÅŸ (u,v) ve Gri Tonlama (g) Pencerelerini OluÅŸturma
# =====================================================================
# Strateji: Script C tarafÄ±ndan Ã¼retilen _flow_u.npy, _flow_v.npy ve
#           _flow_g.npy (gri tonlama) dosyalarÄ±nÄ± okur.
#           Bu 3 kanalÄ± birleÅŸtirir, N_FRAMES uzunluÄŸunda pencereler oluÅŸturur
#           (gerekirse padding yapar) ve .pt dosyalarÄ± olarak kaydeder.
# =====================================================================

import numpy as np
import torch
from pathlib import Path
from tqdm import tqdm # Ä°lerleme Ã§ubuÄŸu iÃ§in
import os # Belki bazÄ± dosya iÅŸlemleri iÃ§in (opsiyonel)

# ----- 1. TEMEL AYARLAR VE YOL TANIMLARI -----
print("--- Script 4-A BaÅŸlatÄ±lÄ±yor: u,v,g_grayscale Pencereleri OluÅŸturma ---")

# Girdi: Script C'nin .npy dosyalarÄ±nÄ± kaydettiÄŸi ana klasÃ¶r
FLOW_ROOT = Path("/content/drive/MyDrive/Crime/Preprocessed_All")

# Ã‡Ä±ktÄ±: OluÅŸturulacak 3 kanallÄ± pencere (.pt) dosyalarÄ±nÄ±n kaydedileceÄŸi ana klasÃ¶r
OUT_ROOT  = Path("/content/drive/MyDrive/Crime/Flow_Windows_32_uvg")
OUT_ROOT.mkdir(parents=True, exist_ok=True) # EÄŸer yoksa oluÅŸtur

# Modelin beklediÄŸi pencere (klip) uzunluÄŸu (zaman boyutu)
N_FRAMES = 32

# Kayan pencereler iÃ§in pencereler arasÄ± kaydÄ±rma adÄ±mÄ±
# EÄŸer orijinal akÄ±ÅŸ N_FRAMES'ten uzunsa bu kullanÄ±lÄ±r.
STRIDE = 15

# Ã‡Ä±ktÄ± pencerelerindeki kanal sayÄ±sÄ± (u, v, g_grayscale)
NUM_CHANNELS = 3

print(f"Girdi .npy KÃ¶k Dizini (FLOW_ROOT): {FLOW_ROOT}")
print(f"Ã‡Ä±ktÄ± .pt Pencere KÃ¶k Dizini (OUT_ROOT): {OUT_ROOT}")
print(f"Pencere UzunluÄŸu (N_FRAMES): {N_FRAMES}")
print(f"Kayan Pencere AdÄ±mÄ± (STRIDE): {STRIDE}")
print(f"Ã‡Ä±ktÄ± Kanal SayÄ±sÄ± (NUM_CHANNELS): {NUM_CHANNELS}")

# ----- 2. Ä°ÅLENECEK DOSYALARIN BULUNMASI -----

# FLOW_ROOT altÄ±ndaki tÃ¼m '_flow_u.npy' dosyalarÄ±nÄ± rekÃ¼rsif olarak bul
# Bu, 'Anomaly-Part-X/KategoriAdi/' gibi alt klasÃ¶rleri de tarar.
try:
    u_files = sorted(list(FLOW_ROOT.rglob("*_flow_u.npy")))
except Exception as e:
    print(f"â€¼ï¸ HATA: {FLOW_ROOT} altÄ±nda dosya aranÄ±rken sorun oluÅŸtu: {e}")
    u_files = [] # Hata durumunda boÅŸ liste ile devam etmeyi dene veya scripti sonlandÄ±r

if not u_files:
    print(f"UYARI: {FLOW_ROOT} dizininde ve alt klasÃ¶rlerinde hiÃ§ '*_flow_u.npy' dosyasÄ± bulunamadÄ±.")
    print("--- Script 4-A Sonu (Ä°ÅŸlenecek dosya yok) ---")
    # exit() # EÄŸer dosya yoksa scripti burada sonlandÄ±rabilirsiniz
else:
    print(f"Toplam {len(u_files)} adet '_flow_u.npy' dosyasÄ± bulundu ve iÅŸlenecek.")

# ----- 3. PENCERELEME VE KAYDETME FONKSÄ°YONU -----

def create_and_save_windows(u_file_path: Path):
    """
    Verilen bir _flow_u.npy dosyasÄ± ve eÅŸlenik _v.npy, _g.npy dosyalarÄ±ndan
    N_FRAMES uzunluÄŸunda pencereler oluÅŸturur ve .pt olarak kaydeder.
    """

    # EÅŸlenik _v.npy ve _g.npy dosyalarÄ±nÄ±n yollarÄ±nÄ± oluÅŸtur
    # Path.with_name, dosya adÄ±nÄ± deÄŸiÅŸtirirken yolu (klasÃ¶rÃ¼) korur.
    v_file_path = u_file_path.with_name(u_file_path.name.replace("_flow_u.npy", "_flow_v.npy"))
    g_file_path = u_file_path.with_name(u_file_path.name.replace("_flow_u.npy", "_flow_g.npy"))

    # DEBUG: Hangi dosyalarÄ±n arandÄ±ÄŸÄ±nÄ± yazdÄ±r
    # tqdm.write(f"ğŸ” Ä°ÅŸlenen u: {u_file_path.name}")
    # tqdm.write(f"     Beklenen v: {v_file_path.name} (Yol: {v_file_path})")
    # tqdm.write(f"     Beklenen g: {g_file_path.name} (Yol: {g_file_path})")

    # EÅŸlenik dosyalarÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
    if not v_file_path.exists():
        tqdm.write(f"âš ï¸ EÅŸlenik v dosyasÄ± ({v_file_path.name}) bulunamadÄ±. AtlanÄ±yor: {u_file_path.name}")
        return 0 # Kaydedilen pencere sayÄ±sÄ±

    if not g_file_path.exists():
        # Bu print, sizin loglarÄ±nÄ±zda gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z "EÅŸlenik g dosyasÄ± bulunamadÄ±" hatasÄ±nÄ± verir.
        tqdm.write(f"âš ï¸ EÅŸlenik g_grayscale dosyasÄ± ({g_file_path.name}) bulunamadÄ±. AtlanÄ±yor: {u_file_path.name}")
        return 0 # Kaydedilen pencere sayÄ±sÄ±

    # DosyalarÄ± yÃ¼kle
    try:
        u_original_data = np.load(u_file_path)      # Beklenen ÅŸekil: (T_flow, H, W)
        v_original_data = np.load(v_file_path)      # Beklenen ÅŸekil: (T_flow, H, W)
        g_original_data = np.load(g_file_path)      # Beklenen ÅŸekil: (T_flow, H, W), deÄŸerler [0,1]
    except Exception as e:
        tqdm.write(f"â€¼ï¸ HATA: {u_file_path.name} veya eÅŸlenik .npy dosyalarÄ± yÃ¼klenirken sorun: {e}")
        return 0

    # YÃ¼klenen dizilerin boyutlarÄ±nÄ± ve frame sayÄ±larÄ±nÄ± kontrol et
    if not (u_original_data.ndim == 3 and v_original_data.ndim == 3 and g_original_data.ndim == 3):
        tqdm.write(f"UYARI: {u_file_path.name} veya eÅŸleniklerinin boyut sayÄ±sÄ± (ndim) 3 deÄŸil. AtlanÄ±yor.")
        return 0

    if not (u_original_data.shape[0] == v_original_data.shape[0] == g_original_data.shape[0]):
        tqdm.write(f"UYARI: {u_file_path.name} iÃ§in u,v,g frame sayÄ±larÄ± eÅŸleÅŸmiyor. AtlanÄ±yor. "
                   f"u:{u_original_data.shape[0]}, v:{v_original_data.shape[0]}, g:{g_original_data.shape[0]}")
        return 0

    # YÃ¼kseklik ve geniÅŸlik (H, W) deÄŸerlerinin de tutarlÄ± olduÄŸunu varsayÄ±yoruz (genellikle 224, 224)
    # OnlarÄ± da kontrol etmek isterseniz:
    # if not (u_original_data.shape[1:] == v_original_data.shape[1:] == g_original_data.shape[1:]):
    #     tqdm.write(f"UYARI: {u_file_path.name} iÃ§in u,v,g H,W boyutlarÄ± eÅŸleÅŸmiyor. AtlanÄ±yor.")
    #     return 0

    current_num_frames = u_original_data.shape[0] # Mevcut akÄ±ÅŸ/gri tonlama kare sayÄ±sÄ±

    # Ã‡Ä±ktÄ± iÃ§in gÃ¶reli klasÃ¶r yapÄ±sÄ±nÄ± FLOW_ROOT'a gÃ¶re belirle
    try:
        relative_dir_structure = u_file_path.parent.relative_to(FLOW_ROOT)
    except ValueError:
        # Bu durum, u_file_path'in FLOW_ROOT altÄ±nda olmamasÄ± gibi beklenmedik bir durumda oluÅŸabilir.
        tqdm.write(f"â€¼ï¸ HATA: {u_file_path} iÃ§in gÃ¶reli yol hesaplanamadÄ± (FLOW_ROOT: {FLOW_ROOT}). AtlanÄ±yor.")
        return 0

    output_target_dir = OUT_ROOT / relative_dir_structure
    output_target_dir.mkdir(parents=True, exist_ok=True) # Gerekirse oluÅŸtur

    # Dosya adÄ±nÄ±n _flow_u kÄ±smÄ±nÄ± Ã§Ä±karÄ±p temel adÄ±nÄ± al
    base_filename_stem = u_file_path.stem.replace("_flow_u", "")

    windows_saved_for_this_clip = 0

    # Durum 1: Mevcut frame sayÄ±sÄ± N_FRAMES'ten KISA ise DOLDURMA (padding) yap
    if current_num_frames < N_FRAMES:
        if current_num_frames == 0: # HiÃ§ frame yoksa atla
            tqdm.write(f"â„¹ï¸ {u_file_path.name} hiÃ§ frame iÃ§ermiyor (uzunluk: {current_num_frames}). AtlanÄ±yor.")
            return 0

        padding_size = N_FRAMES - current_num_frames
        # ((Ã¶ncesine_pad, sonrasÄ±na_pad), (H_Ã¶n, H_son), (W_Ã¶n, W_son))
        # Sadece zaman (ilk) boyutta sona doÄŸru padding yapÄ±yoruz.
        pad_width = ((0, padding_size), (0,0), (0,0))
        try:
            u_padded = np.pad(u_original_data, pad_width, mode='edge')
            v_padded = np.pad(v_original_data, pad_width, mode='edge')
            g_padded = np.pad(g_original_data, pad_width, mode='edge')
        except Exception as e:
            tqdm.write(f"â€¼ï¸ HATA: {u_file_path.name} iÃ§in padding sÄ±rasÄ±nda hata: {e}")
            return 0

        # Doldurma sonrasÄ± tek bir pencere oluÅŸur
        u_window, v_window, g_window = u_padded, v_padded, g_padded

        # KanallarÄ± birleÅŸtir: (3, N_FRAMES, H, W)
        stacked_channels_clip = np.stack([u_window, v_window, g_window], axis=0)
        stacked_channels_clip = stacked_channels_clip.astype(np.float32) # Veri tipini float32 yap

        # DoldurulmuÅŸ klipler iÃ§in tek bir pencere (Ã¶rn: _win00000.pt)
        output_pt_filename = output_target_dir / f"{base_filename_stem}_win{0:05d}.pt"
        try:
            torch.save(torch.from_numpy(stacked_channels_clip), output_pt_filename)
            windows_saved_for_this_clip = 1
            # tqdm.write(f"â„¹ï¸ Klip {u_file_path.stem} (uzunluk: {current_num_frames}) {N_FRAMES}'e DOLDURULDU ve '{output_pt_filename.name}' olarak kaydedildi.")
        except Exception as e:
            tqdm.write(f"â€¼ï¸ HATA: {output_pt_filename.name} dosyasÄ± kaydedilirken sorun: {e}")

    # Durum 2: Mevcut frame sayÄ±sÄ± N_FRAMES'e EÅÄ°T veya DAHA UZUN ise kayan pencere uygula
    else:
        for s in range(0, current_num_frames - N_FRAMES + 1, STRIDE):
            u_window = u_original_data[s : s + N_FRAMES]
            v_window = v_original_data[s : s + N_FRAMES]
            g_window = g_original_data[s : s + N_FRAMES]

            stacked_channels_clip = np.stack([u_window, v_window, g_window], axis=0)
            stacked_channels_clip = stacked_channels_clip.astype(np.float32)

            output_pt_filename = output_target_dir / f"{base_filename_stem}_win{s:05d}.pt"
            try:
                torch.save(torch.from_numpy(stacked_channels_clip), output_pt_filename)
                windows_saved_for_this_clip += 1
            except Exception as e:
                tqdm.write(f"â€¼ï¸ HATA: {output_pt_filename.name} dosyasÄ± kaydedilirken sorun: {e}")
        # if windows_saved_for_this_clip > 0:
        #     tqdm.write(f"â„¹ï¸ Klip {u_file_path.stem} iÃ§in {windows_saved_for_this_clip} pencere kaydedildi.")

    return windows_saved_for_this_clip

# ----- 4. TOPLU Ä°ÅLEME DÃ–NGÃœSÃœ -----
total_windows_created = 0
if u_files: # EÄŸer iÅŸlenecek .npy dosyasÄ± bulunduysa
    for u_single_file_path in tqdm(u_files, desc="Pencereler oluÅŸturuluyor (u,v,g_gray)"):
        total_windows_created += create_and_save_windows(u_single_file_path)
    print(f"\nToplam {total_windows_created} pencere .pt dosyasÄ± oluÅŸturuldu.")
else:
    print("Ä°ÅŸlenecek _flow_u.npy dosyasÄ± bulunmadÄ±ÄŸÄ± iÃ§in pencere oluÅŸturma iÅŸlemi yapÄ±lmadÄ±.")

print(f"âœ… Script 4-A TamamlandÄ±. Pencereler '{OUT_ROOT}' klasÃ¶rÃ¼ne kaydedilmeye Ã§alÄ±ÅŸÄ±ldÄ±.")

# ----- 5. (OPSÄ°YONEL) KONTROL -----
# OUT_ROOT altÄ±ndaki .pt dosyalarÄ±nÄ±n sayÄ±sÄ±nÄ± kontrol edebilirsiniz:
# !find "/content/drive/MyDrive/Crime/Flow_Windows_32_uvg" -name "*.pt" | wc -l

!tree -L 2 /content/drive/MyDrive/Crime/Flow_Windows_32 | head -n 40

"""### **4-B â–¸ PyTorch Dataset & DataLoader**"""

# ---------- 4-B â–¸ PyTorch Dataset & DataLoader (u,v,g_grayscale) ----------
from pathlib import Path
import torch
from torch.utils.data import Dataset, DataLoader
import random
import traceback # Hata ayÄ±klama iÃ§in

# FLOW32_ROOT, Script 4-A'nÄ±n Ã‡IKIÅ KLASÃ–RÃœ olmalÄ±
FLOW32_ROOT = Path("/content/drive/MyDrive/Crime/Flow_Windows_32_uvg")
N_FRAMES = 32 # Script 4-A'daki N_FRAMES ile aynÄ± olmalÄ±

print(f"--- Script 4-B BaÅŸlatÄ±lÄ±yor ---")
print(f"KullanÄ±lacak Pencere DosyalarÄ± KÃ¶k Dizini (FLOW32_ROOT): {FLOW32_ROOT}")
print(f"Beklenen Frame SayÄ±sÄ± (N_FRAMES): {N_FRAMES}")

# Etiketleme fonksiyonu
def is_anomaly(p: Path) -> int:
    """
    Dosya yoluna bakarak anomali (1) veya normal (0) etiketi Ã¼retir.
    Yolun herhangi bir kÄ±smÄ±nda 'normal' kelimesi (bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z) geÃ§erse normal kabul edilir.
    """
    try:
        # FLOW32_ROOT'a gÃ¶reli yola bakmak yerine doÄŸrudan tÃ¼m yola bakmak daha genel olabilir.
        # Ã‡Ã¼nkÃ¼ p.parts tÃ¼m yol segmentlerini iÃ§erir.
        for part_name in p.parts:
            if "normal" in part_name.lower():
                return 0 # Normal
    except Exception as e:
        print(f"is_anomaly iÃ§inde hata ({p}): {e}") # Hata durumunda logla
        pass
    return 1 # Anomaly (eÄŸer 'normal' bulunamazsa veya bir hata oluÅŸursa)

# Ã–rnek testler (isteÄŸe baÄŸlÄ±, Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce yollarÄ±n varlÄ±ÄŸÄ±ndan emin olun)
# print("\n--- is_anomaly Fonksiyon Testleri ---")
# test_anomaly_file = FLOW32_ROOT / "Anomaly-Part-1" / "Abuse" / "Abuse001_x264win00000.pt" # Ã–rnek dosya adÄ±
# test_normal_file = FLOW32_ROOT / "Training-Normal-1" / "Normal_Videos_001_x264win00000.pt" # Ã–rnek dosya adÄ±
#
# if test_anomaly_file.exists():
#     print(f"'{test_anomaly_file.name}' iÃ§in etiket: {is_anomaly(test_anomaly_file)} (Beklenen: 1)")
# else:
#     print(f"Test dosyasÄ± bulunamadÄ±: {test_anomaly_file}")
#
# if test_normal_file.exists():
#     print(f"'{test_normal_file.name}' iÃ§in etiket: {is_anomaly(test_normal_file)} (Beklenen: 0)")
# else:
#     print(f"Test dosyasÄ± bulunamadÄ±: {test_normal_file}")


class FlowWindowDataset(Dataset):
    """(3, N_FRAMES, 224, 224) flow window (u,v,g_grayscale) + binary label"""
    def __init__(self, root: Path, n_frames: int, split="all", seed=42):
        self.root = root
        self.n_frames = n_frames

        print(f"\n'{self.split_name(split)}' Veri Seti iÃ§in '{root}' taranÄ±yor (beklenen frame sayÄ±sÄ±: {n_frames})...")

        if not root.exists() or not root.is_dir():
            print(f"UYARI: Belirtilen kÃ¶k dizin '{root}' bulunamadÄ± veya bir klasÃ¶r deÄŸil!")
            self.paths = []
            return # Hata durumunda boÅŸ dataset ile devam et

        paths = sorted([p for p in root.rglob("*win*.pt")]) # _win iÃ§eren .pt dosyalarÄ±

        if not paths:
            print(f"UYARI: '{root}' altÄ±nda hiÃ§ '*win*.pt' dosyasÄ± bulunamadÄ±!")

        if split != "all" and paths: # paths boÅŸ deÄŸilse split yap
            random.Random(seed).shuffle(paths)
            cut = int(len(paths) * 0.8) # %80 train, %20 val
            if split == "train":
                paths = paths[:cut]
            elif split == "val": # "val" veya "test" iÃ§in
                paths = paths[cut:]
            else: # TanÄ±msÄ±z split adÄ±
                print(f"UYARI: TanÄ±msÄ±z split adÄ± '{split}'. TÃ¼m veriler kullanÄ±lÄ±yor.")

        self.paths = paths

        if not self.paths:
             print(f"UYARI: '{self.split_name(split)}' veri seti iÃ§in hiÃ§ dosya yÃ¼klenemedi/bulunamadÄ± (`self.paths` boÅŸ).")
        else:
             print(f"-> '{self.split_name(split)}' veri seti iÃ§in {len(self.paths)} dosya bulundu.")

    def split_name(self, split_val):
        if split_val == "all": return "TÃ¼mÃ¼"
        if split_val == "train": return "EÄŸitim"
        if split_val == "val": return "DoÄŸrulama"
        return split_val # Bilinmeyen split adÄ± iÃ§in olduÄŸu gibi dÃ¶ndÃ¼r

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        if idx >= len(self.paths): # OlasÄ± bir index hatasÄ±nÄ± Ã¶nle
            print(f"HATA: GeÃ§ersiz index {idx}, dataset boyutu {len(self.paths)}")
            return None

        p = self.paths[idx]
        try:
            clip = torch.load(p, map_location="cpu") # (3, N_FRAMES, H, W)
        except Exception as e:
            print(f"â€¼ï¸ HATA: {p.name} yÃ¼klenirken sorun: {e}. Bu Ã¶rnek atlanacak.")
            return None

        if not isinstance(clip, torch.Tensor):
            print(f"UYARI: {p.name} geÃ§erli bir tensor yÃ¼klemedi (tip: {type(clip)}). Atlanacak.")
            return None

        if clip.shape[0] != NUM_CHANNELS or clip.shape[1] != self.n_frames: # NUM_CHANNELS global olmalÄ± (veya parametre)
            print(f"UYARI: {p.name} beklenmedik boyutta: {clip.shape}. Beklenen ({NUM_CHANNELS}, {self.n_frames}, H, W). Atlanacak.")
            return None

        y = torch.tensor(is_anomaly(p), dtype=torch.long)
        return clip, y

# None (hatalÄ±/atlanmÄ±ÅŸ) Ã¶rnekleri DataLoader'da filtrelemek iÃ§in collate_fn
def collate_fn_skip_none(batch):
    # Gelen batch'i None olmayanlarla filtrele
    valid_batch = [item for item in batch if item is not None]

    if not valid_batch: # EÄŸer tÃ¼m batch (veya tek elemanlÄ± batch) None ise
        # print("UYARI: collate_fn_skip_none: TÃ¼m batch None, bu durum sorun yaratabilir.")
        return None # Ã‡aÄŸÄ±ran kodun bunu iÅŸlemesi gerekir (Ã¶rn: DataLoader dÃ¶ngÃ¼sÃ¼nde if batch_data is None: continue)

    # GeÃ§erli Ã¶ÄŸeler varsa, standart PyTorch collate fonksiyonunu kullan
    try:
        return torch.utils.data.dataloader.default_collate(valid_batch)
    except RuntimeError as e: # EÄŸer collate sÄ±rasÄ±nda bir hata olursa (Ã¶rn: tensor boyutlarÄ± eÅŸleÅŸmiyorsa)
        print(f"HATA: collate_fn_skip_none iÃ§inde default_collate hatasÄ±: {e}")
        # HatalÄ± durumu anlamak iÃ§in batch iÃ§eriÄŸini yazdÄ±rabilirsiniz
        # for i, item in enumerate(valid_batch):
        #     if item is not None and isinstance(item, tuple) and len(item) > 0 and isinstance(item[0], torch.Tensor):
        #         print(f"  valid_batch[{i}] tensor ÅŸekli: {item[0].shape}")
        #     else:
        #         print(f"  valid_batch[{i}] beklenmedik yapÄ±da: {item}")
        return None # Hata durumunda None dÃ¶ndÃ¼r

# Script 4-A'dan gelen NUM_CHANNELS deÄŸiÅŸkenini burada da tanÄ±mlayalÄ±m (FlowWindowDataset iÃ§inde kullanÄ±lÄ±yor)
NUM_CHANNELS = 3 # u,v,g_grayscale

print(f"\n--- DataLoader Ã–rnek KullanÄ±mÄ± (N_FRAMES={N_FRAMES}) ---")
try:
    # Dataset nesnelerini oluÅŸtur
    train_ds = FlowWindowDataset(FLOW32_ROOT, n_frames=N_FRAMES, split="train")
    val_ds   = FlowWindowDataset(FLOW32_ROOT, n_frames=N_FRAMES, split="val")

    # Sadece dataset'ler boÅŸ deÄŸilse DataLoader oluÅŸtur
    if len(train_ds) > 0 and len(val_ds) > 0:
        BATCH_SIZE = 4 # Deneyler iÃ§in kÃ¼Ã§Ã¼k bir batch boyutu
        WORKERS    = 2 # Colab iÃ§in genellikle 2 iyi bir baÅŸlangÄ±Ã§tÄ±r
        PIN_MEMORY = torch.cuda.is_available() # GPU varsa pin_memory kullan

        train_loader = DataLoader(train_ds,
                                  batch_size=BATCH_SIZE,
                                  shuffle=True,
                                  num_workers=WORKERS,
                                  pin_memory=PIN_MEMORY,
                                  collate_fn=collate_fn_skip_none,
                                  drop_last=True) # EÄŸitimde son, tam olmayan batch'i atla

        val_loader   = DataLoader(val_ds,
                                  batch_size=BATCH_SIZE,
                                  shuffle=False,
                                  num_workers=WORKERS,
                                  pin_memory=PIN_MEMORY,
                                  collate_fn=collate_fn_skip_none)

        print(f"\nTrain DataLoader: {len(train_ds):,} pencere, {len(train_loader) if train_loader else 0} batch.")
        print(f"Val   DataLoader: {len(val_ds):,} pencere, {len(val_loader) if val_loader else 0} batch.")

        # HÄ±zlÄ± bir "sanity check" (saÄŸlamlÄ±k kontrolÃ¼)
        print("\n--- Sanity Check: EÄŸitim DataLoader'dan Ã–rnek Batch ---")
        if train_loader and len(train_loader) > 0:
            batch_sample = next(iter(train_loader)) # Ä°lk batch'i al

            if batch_sample is not None: # collate_fn None dÃ¶ndÃ¼rmediyse
                x_batch, y_batch = batch_sample
                print("Ã–rnek batch tensÃ¶r ve etiket boyutlarÄ±:")
                print(f"  x_batch.shape: {x_batch.shape}") # Beklenen: [BATCH_SIZE, NUM_CHANNELS, N_FRAMES, YÃ¼kseklik, GeniÅŸlik]
                print(f"  y_batch.shape: {y_batch.shape}") # Beklenen: [BATCH_SIZE]
                if x_batch.numel() > 0 : # EÄŸer batch boÅŸ deÄŸilse
                    print(f"  Bu batch'teki anomali oranÄ± (yaklaÅŸÄ±k): {y_batch.float().mean().item():.3f}")
            else:
                print("Sanity check iÃ§in train_loader'dan geÃ§erli bir batch alÄ±namadÄ± (muhtemelen tÃ¼m Ã¶rnekler hatalÄ±ydÄ±).")
        else:
            print("Sanity check iÃ§in train_loader boÅŸ veya oluÅŸturulamadÄ±.")
    else:
        print("\nUYARI: EÄŸitim veya doÄŸrulama veri seti boÅŸ olduÄŸu iÃ§in DataLoader'lar oluÅŸturulmadÄ±.")
        print("LÃ¼tfen FLOW32_ROOT yolunun doÄŸru olduÄŸundan ve Script 4-A'nÄ±n baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±p .pt dosyalarÄ± Ã¼rettiÄŸinden emin olun.")

except FileNotFoundError as fnf_err:
    print(f"â€¼ï¸ HATA (Dosya BulunamadÄ±): {fnf_err}")
    print(f"LÃ¼tfen FLOW32_ROOT yolunun ('{FLOW32_ROOT}') doÄŸru olduÄŸundan ve Script 4-A'nÄ±n .pt dosyalarÄ±nÄ± bu klasÃ¶re oluÅŸturduÄŸundan emin olun.")
except Exception as e:
    print(f"â€¼ï¸ HATA: Dataset/DataLoader oluÅŸturulurken genel bir sorun oluÅŸtu: {e}")
    print(traceback.format_exc())

print("\n--- Script 4-B TamamlandÄ± ---")

"""### 4-C â–¸ ViViT-B-16Ã—2 modelini yÃ¼kleme (+ GPUâ€™ya taÅŸÄ±ma, Fine Tune'a hazÄ±rlÄ±k)"""

#Â B) doÄŸru sÃ¼rÃ¼mÃ¼ kurun  (0.1.5 son kararlÄ±, 0.1.3 de olur)
!pip install pytorchvideo==0.1.5            # veya 0.1.3
!pip install --upgrade einops safetensors   # 4â€‘C kodunuz iÃ§in
!pip install transformers torch accelerate # Accelerate genellikle Ã¶nerilir

# =====================================================================
# Script 4-C: ViViT Modelini YÃ¼kleme ve Uyarlama (u,v,g_grayscale iÃ§in)
# =====================================================================
# Strateji: Hugging Face'den Ã¶nceden eÄŸitilmiÅŸ ViViT modelini yÃ¼kler.
#           GiriÅŸ katmanÄ±nÄ± 3 kanallÄ± (u,v,g_grayscale) girdiyi kabul
#           edecek ÅŸekilde uyarlar. SÄ±nÄ±flandÄ±rÄ±cÄ± katmanÄ±nÄ± kendi
#           problemimizdeki sÄ±nÄ±f sayÄ±sÄ±na gÃ¶re ayarlar.
#           Belirli katmanlarÄ± dondurup, bazÄ±larÄ±nÄ± eÄŸitim iÃ§in aÃ§ar.
# =====================================================================

import torch
import torch.nn as nn
import torch.optim as optim # Optimizer tanÄ±mlamasÄ± iÃ§in
from transformers import AutoModelForVideoClassification
from pathlib import Path # Gerekirse diye eklendi, doÄŸrudan kullanÄ±lmÄ±yor olabilir
import traceback # Hata ayÄ±klama iÃ§in

print("--- Script 4-C BaÅŸlatÄ±lÄ±yor: ViViT Modeli YÃ¼kleme ve Uyarlama ---")

# ----- 1. TEMEL YAPILANDIRMA -----
MODEL_NAME_HF = "prathameshdalal/vivit-b-16x2-kinetics400-UCF-Crime"
NUM_CLASSES = 14  # Sizin projenizdeki hedef sÄ±nÄ±f sayÄ±sÄ±
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"KullanÄ±lacak Cihaz: {DEVICE}")
print(f"Hedef SÄ±nÄ±f SayÄ±sÄ±: {NUM_CLASSES}")

# Diferansiyel Ã–ÄŸrenme OranlarÄ± (PreTrain bÃ¶lÃ¼mÃ¼nÃ¼zdeki gibi)
LR_CLASSIFIER = 3e-4
LR_PATCH_EMBED_PROJECTION = 5e-4 # Sadece projeksiyon katmanÄ± iÃ§in veya tÃ¼m patch_embeddings iÃ§in
LR_ENCODER_UNFROZEN_BLOCKS = 3e-5
WEIGHT_DECAY_CONFIG = 1e-2

hf_model = None # Modeli bu script kapsamÄ±nda tanÄ±mlayÄ±p hazÄ±rlayacaÄŸÄ±z
model_ready_for_training = False
optimizer = None

# ----- 2. MODELÄ° YÃœKLEME VE UYARLAMA -----
try:
    print(f"\n'{MODEL_NAME_HF}' modeli Hugging Face'den yÃ¼kleniyor...")
    hf_model_base = AutoModelForVideoClassification.from_pretrained(MODEL_NAME_HF)
    print(f"-> Model baÅŸarÄ±yla yÃ¼klendi. Orijinal veri tipi: {next(hf_model_base.parameters()).dtype}")

    # --- 2a. SÄ±nÄ±flandÄ±rÄ±cÄ± (Classifier) KatmanÄ±nÄ± DeÄŸiÅŸtirme ---
    original_num_classes = hf_model_base.classifier.out_features
    if original_num_classes != NUM_CLASSES:
        in_features = hf_model_base.classifier.in_features
        hf_model_base.classifier = torch.nn.Linear(in_features, NUM_CLASSES)
        print(f"-> SÄ±nÄ±flandÄ±rÄ±cÄ± katmanÄ± {original_num_classes} sÄ±nÄ±ftan {NUM_CLASSES} sÄ±nÄ±fa deÄŸiÅŸtirildi.")
    else:
        print(f"-> SÄ±nÄ±flandÄ±rÄ±cÄ± katmanÄ± zaten {NUM_CLASSES} sÄ±nÄ±flÄ±.")

    # --- 2b. GiriÅŸ Projeksiyon KatmanÄ±nÄ± 3 Kanala (u,v,g_grayscale) Uyarlama ---
    print("GiriÅŸ projeksiyon katmanÄ± 3 KANAL (u,v,g_grayscale) iÃ§in uyarlanÄ±yor...")
    original_proj_layer = hf_model_base.vivit.embeddings.patch_embeddings.projection

    # Orijinal projeksiyon katmanÄ±nÄ±n parametrelerini al
    original_in_channels = original_proj_layer.in_channels
    out_channels = original_proj_layer.out_channels
    kernel_size = original_proj_layer.kernel_size
    stride = original_proj_layer.stride
    padding = original_proj_layer.padding
    dilation = original_proj_layer.dilation
    groups = original_proj_layer.groups
    has_bias = (original_proj_layer.bias is not None)
    print(f"  Orijinal projeksiyon katmanÄ±: in_channels={original_in_channels}, out_channels={out_channels}, kernel_size={kernel_size}")

    # Yeni projeksiyon katmanÄ±nÄ± bizim 3 giriÅŸ kanalÄ±mÄ±z iÃ§in oluÅŸtur
    # (u,v,g_grayscale de 3 kanal olduÄŸu iÃ§in in_channels=3 olacak)
    new_in_channels = 3
    new_projection_layer = nn.Conv3d(
        in_channels=new_in_channels,
        out_channels=out_channels,
        kernel_size=kernel_size,
        stride=stride,
        padding=padding,
        dilation=dilation,
        groups=groups,
        bias=has_bias
    )

    with torch.no_grad(): # Gradyan hesaplamasÄ±nÄ± bu blokta durdur
        # Orijinal aÄŸÄ±rlÄ±klarÄ± (genellikle RGB iÃ§in [out_ch, 3, Kt, Kh, Kw]) al
        original_weights = original_proj_layer.weight.data

        if original_in_channels == 3: # EÄŸer orijinal model RGB (3 kanal) ise
            # Strateji: Orijinal RGB aÄŸÄ±rlÄ±klarÄ±nÄ±n ortalamasÄ±nÄ± alÄ±p yeni 3 kanal iÃ§in kullan.
            # Bu, her Ã§Ä±kÄ±ÅŸ filtresi iÃ§in R,G,B aÄŸÄ±rlÄ±klarÄ±nÄ±n ortalamasÄ±nÄ± alÄ±r.
            mean_original_channel_weights = torch.mean(original_weights, dim=1, keepdim=True)
            # Bu ortalama aÄŸÄ±rlÄ±ÄŸÄ± bizim yeni 3 kanalÄ±mÄ±z (u,v,g_grayscale) iÃ§in tekrarla.
            adapted_weights = mean_original_channel_weights.repeat(1, new_in_channels, 1, 1, 1)
            new_projection_layer.weight.data.copy_(adapted_weights)
            print("  -> Projeksiyon katmanÄ± aÄŸÄ±rlÄ±klarÄ±, orijinal 3 (RGB) kanal aÄŸÄ±rlÄ±klarÄ±nÄ±n ortalamasÄ± alÄ±narak "
                  f"yeni {new_in_channels} (u,v,g_grayscale) kanal iÃ§in kopyalandÄ±.")
        else:
            # Orijinal model 3 kanallÄ± deÄŸilse (beklenmedik durum) veya farklÄ± bir strateji izlemek isterseniz.
            # Åimdilik, eÄŸer orijinal 3 deÄŸilse, yeni katman rastgele baÅŸlatÄ±lmÄ±ÅŸ aÄŸÄ±rlÄ±klarÄ±yla kalÄ±r.
            # Ya da isterseniz burada hata verebilir veya farklÄ± bir baÅŸlatma yapabilirsiniz.
            print(f"  UYARI: Orijinal projeksiyon katmanÄ± {original_in_channels} kanallÄ±ydÄ± (3 deÄŸil). "
                  f"Yeni {new_in_channels} kanallÄ± katmanÄ±n aÄŸÄ±rlÄ±klarÄ± varsayÄ±lan (rastgele) baÅŸlatma ile bÄ±rakÄ±ldÄ±.")

        if has_bias and new_projection_layer.bias is not None:
            new_projection_layer.bias.data.copy_(original_proj_layer.bias.data)
            print("  -> Projeksiyon katmanÄ± bias'Ä± (varsa) kopyalandÄ±.")

    # Yeni oluÅŸturulan ve aÄŸÄ±rlÄ±klarÄ± uyarlanan katmanÄ± modele ata
    hf_model_base.vivit.embeddings.patch_embeddings.projection = new_projection_layer
    hf_model = hf_model_base # Modeli hf_model deÄŸiÅŸkenine ata
    print(f"  -> Yeni projeksiyon katmanÄ± (in_channels={new_in_channels}) modele atandÄ±. "
          f"AÄŸÄ±rlÄ±k ÅŸekli: {new_projection_layer.weight.shape}")

    # --- 2c. KatmanlarÄ± Dondurma / EÄŸitime AÃ§ma ---
    # "PreTrain" bÃ¶lÃ¼mÃ¼nÃ¼zdeki stratejiyi izleyerek:
    #   - Ã–nce tÃ¼m parametreleri dondur.
    #   - Sonra sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ±, tÃ¼m patch embeddings modÃ¼lÃ¼nÃ¼ ve encoder'Ä±n son birkaÃ§ bloÄŸunu aÃ§.
    print("Katmanlar donduruluyor ve belirtilenler eÄŸitime aÃ§Ä±lÄ±yor...")
    for param_name, param in hf_model.named_parameters():
        param.requires_grad = False # Ã–nce tÃ¼mÃ¼nÃ¼ dondur

    # SÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± (classifier) eÄŸitilebilir yap
    for param_name, param in hf_model.classifier.named_parameters():
        param.requires_grad = True
    print("  -> SÄ±nÄ±flandÄ±rÄ±cÄ± (classifier) katmanÄ± eÄŸitilebilir yapÄ±ldÄ±.")

    # TÃ¼m Patch Embeddings modÃ¼lÃ¼nÃ¼ (projeksiyon dahil) eÄŸitilebilir yap
    # (vivit.embeddings.patch_embeddings)
    for param_name, param in hf_model.vivit.embeddings.patch_embeddings.named_parameters():
        param.requires_grad = True
    print("  -> TÃ¼m Patch Embeddings modÃ¼lÃ¼ (patch_embeddings) eÄŸitilebilir yapÄ±ldÄ±.")

    # ViViT encoder bloklarÄ±nÄ±n bir kÄ±smÄ±nÄ± aÃ§ (opsiyonel, "PreTrain"deki gibi son 6 blok)
    if hasattr(hf_model, 'vivit') and hasattr(hf_model.vivit, 'encoder') and hasattr(hf_model.vivit.encoder, 'layer'):
        total_encoder_blocks = len(hf_model.vivit.encoder.layer)
        num_blocks_to_unfreeze_target = 6 # EÄŸitime aÃ§Ä±lacak son blok sayÄ±sÄ±

        num_blocks_to_unfreeze = 0
        if total_encoder_blocks > 0:
            num_blocks_to_unfreeze = min(num_blocks_to_unfreeze_target, total_encoder_blocks)
            if num_blocks_to_unfreeze_target > total_encoder_blocks:
                print(f"  UYARI: Ä°stenen {num_blocks_to_unfreeze_target} aÃ§Ä±lacak blok sayÄ±sÄ±, toplam {total_encoder_blocks} bloktan fazla. "
                      f"Son {total_encoder_blocks} blok aÃ§Ä±lacak.")
            elif num_blocks_to_unfreeze_target <= 0:
                 num_blocks_to_unfreeze = 0 # HiÃ§ blok aÃ§ma

        if num_blocks_to_unfreeze > 0:
            print(f"  -> ViViT encoder'Ä±n son {num_blocks_to_unfreeze} bloÄŸu (toplam {total_encoder_blocks} bloktan) eÄŸitilebilir yapÄ±lÄ±yor:")
            for i in range(total_encoder_blocks - num_blocks_to_unfreeze, total_encoder_blocks):
                print(f"      Encoder blok {i} aÃ§Ä±lÄ±yor...")
                for param_name, param in hf_model.vivit.encoder.layer[i].named_parameters():
                    param.requires_grad = True
        elif total_encoder_blocks > 0 : # num_blocks_to_unfreeze == 0 ise
             print("  -> ViViT encoder bloklarÄ± eÄŸitilebilir yapÄ±lmayacak (0 blok hedeflendi).")
        else: # total_encoder_blocks == 0 ise
            print("  Encoder'da aÃ§Ä±labilecek blok bulunmuyor (muhtemelen model yapÄ±sÄ± farklÄ±).")
    else:
        print("  UYARI: Model yapÄ±sÄ± beklenenden farklÄ± (vivit.encoder.layer bulunamadÄ±), encoder bloklarÄ± otomatik aÃ§Ä±lamadÄ±.")

    # --- 2d. Modeli Cihaza TaÅŸÄ±ma ve Son Kontroller ---
    hf_model.to(DEVICE)
    print(f"Model '{DEVICE}' cihazÄ±na taÅŸÄ±ndÄ± (Veri tipi: FP32).")

    num_total_params = sum(p.numel() for p in hf_model.parameters())
    num_trainable_params = sum(p.numel() for p in hf_model.parameters() if p.requires_grad)
    print(f"\nModel Parametreleri:")
    print(f"  Toplam parametre sayÄ±sÄ±    : {num_total_params:,}")
    print(f"  EÄŸitilebilir parametre sayÄ±sÄ±: {num_trainable_params:,} (%{100 * num_trainable_params / num_total_params:.2f})")

    model_ready_for_training = True
    print("\n--- Model HazÄ±rlÄ±ÄŸÄ± (3-Kanal u,v,g_grayscale iÃ§in) TamamlandÄ± ---")

except Exception as e:
    print(f"â€¼ï¸ HATA: Script 4-C'de model yÃ¼kleme veya uyarlama sÄ±rasÄ±nda bir sorun oluÅŸtu: {e}")
    print(traceback.format_exc())

# ----- 3. OPTIMIZER TANIMLAMASI (PreTrain bÃ¶lÃ¼mÃ¼ndeki gibi diferansiyel LR ile) -----
# Bu kÄ±sÄ±m, model baÅŸarÄ±yla hazÄ±rlandÄ±ysa ve eÄŸitim script'inizin bir parÃ§asÄ±ysa Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.
# EÄŸer optimizer'Ä± ana eÄŸitim dÃ¶ngÃ¼sÃ¼nde tanÄ±mlÄ±yorsanÄ±z, bu bloÄŸu orada kullanabilirsiniz.
if model_ready_for_training and hf_model is not None:
    print("\nOptimizer (AdamW) diferansiyel Ã¶ÄŸrenme oranlarÄ±yla tanÄ±mlanÄ±yor...")

    param_groups = []

    # SÄ±nÄ±flandÄ±rÄ±cÄ± parametreleri
    classifier_params = [p for n, p in hf_model.named_parameters() if 'classifier' in n and p.requires_grad]
    if classifier_params:
        param_groups.append({'params': classifier_params, 'lr': LR_CLASSIFIER, 'name': 'classifier'})
        print(f"  -> Classifier parametreleri ({sum(p.numel() for p in classifier_params):,}) iÃ§in LR: {LR_CLASSIFIER}")

    # Patch Embeddings (projeksiyon dahil) parametreleri
    patch_embed_params = [p for n, p in hf_model.named_parameters() if 'vivit.embeddings.patch_embeddings' in n and p.requires_grad]
    if patch_embed_params:
        param_groups.append({'params': patch_embed_params, 'lr': LR_PATCH_EMBED_PROJECTION, 'name': 'patch_embeddings'})
        print(f"  -> Patch Embeddings parametreleri ({sum(p.numel() for p in patch_embed_params):,}) iÃ§in LR: {LR_PATCH_EMBED_PROJECTION}")

    # Geri kalan eÄŸitilebilir backbone parametreleri (aÃ§Ä±lan encoder bloklarÄ± vb.)
    other_trainable_backbone_params = [
        p for n, p in hf_model.named_parameters()
        if p.requires_grad and
           'classifier' not in n and
           'vivit.embeddings.patch_embeddings' not in n
    ]
    if other_trainable_backbone_params:
        param_groups.append({'params': other_trainable_backbone_params, 'lr': LR_ENCODER_UNFROZEN_BLOCKS, 'name': 'opened_encoder_blocks'})
        print(f"  -> DiÄŸer aÃ§Ä±lmÄ±ÅŸ backbone parametreleri ({sum(p.numel() for p in other_trainable_backbone_params):,}) iÃ§in LR: {LR_ENCODER_UNFROZEN_BLOCKS}")

    if param_groups:
        optimizer = optim.AdamW(param_groups, weight_decay=WEIGHT_DECAY_CONFIG)
        print(f"-> Diferansiyel AdamW optimizer baÅŸarÄ±yla tanÄ±mlandÄ±. Weight Decay: {WEIGHT_DECAY_CONFIG}")
    else:
        print("UYARI: Optimizer iÃ§in hiÃ§ eÄŸitilebilir parametre grubu bulunamadÄ±!")
        optimizer = None # Hata durumunda optimizer'Ä± None yap
else:
    if not model_ready_for_training:
        print("\nModel hazÄ±rlanamadÄ±ÄŸÄ± iÃ§in optimizer tanÄ±mlanmadÄ±.")

# ArtÄ±k `hf_model` ve `optimizer` (eÄŸer tanÄ±mlandÄ±ysa) ana eÄŸitim dÃ¶ngÃ¼nÃ¼zde kullanÄ±lmaya hazÄ±rdÄ±r.
# EÄŸitim iÃ§in bir `scaler` (torch.cuda.amp.GradScaler) de gerekebilir eÄŸer AMP kullanacaksanÄ±z.
# `USING_HALF = False` (veya True) ve `scaler = torch.cuda.amp.GradScaler(enabled=USING_HALF)`
# tanÄ±mlamalarÄ±nÄ± eÄŸitim dÃ¶ngÃ¼nÃ¼zÃ¼n baÅŸÄ±na ekleyebilirsiniz.